{
    "_documentation": {
        "how_to_add_models": "For GGUF, specify 'filename'. Wildcards (*) allowed.",
        "tasks": ["text-generation", "image-to-text", "feature-extraction", "automatic-speech-recognition"]
    },
    
    "Qwen/Qwen2.5-3B-Instruct-GGUF": {
        "description": "Generation model. GGUF Q4_K_M.",
        "task": "text-generation",
        "filename": "*q4_k_m.gguf",
        "system_prompt": "You are Qwen, a helpful assistant.",
        "generation_defaults": {
            "n_ctx": 0,          
            "n_gpu_layers": -1
        }
    },
    "unsloth/Qwen2.5-VL-3B-Instruct-GGUF": {
        "description": "Vision Language Model.",
        "task": "image-to-text",
        "filename": "*Q4_K_M.gguf",
        "projector_filename": "*mmproj*.gguf",
        "chat_handler": "llama_cpp.llama_chat_format.Qwen2VLChatHandler",
        "generation_defaults": {
            "n_ctx": 0,          
            "n_gpu_layers": -1
        }
    },
    "sentence-transformers/all-MiniLM-L6-v2": {
        "description": "Embeddings (Transformers backend).",
        "task": "feature-extraction",
        "backend": "transformers"
    },
    "openai/whisper-small": {
        "description": "Whisper ASR (Transformers backend).",
        "task": "automatic-speech-recognition",
        "backend": "transformers"
    },
    "BAAI/bge-reranker-v2-m3": {
        "description": "Reranker (Transformers backend).",
        "task": "feature-extraction",
        "backend": "transformers"
    },
    "Qwen/Qwen3-4B-GGUF": {
        "description": "Generation model. GGUF Q4_K_M.",
        "task": "text-generation",
        "filename": "*Q4_K_M.gguf",
        "system_prompt": "You are Qwen, a helpful assistant.",
        "generation_defaults": {
            "n_ctx": 0,          
            "n_gpu_layers": -1
        }
    },

    "Qwen/Qwen2.5-72B-Instruct-GGUF": {
        "description": "Generation model. GGUF Q4_K_M.",
        "task": "text-generation",
        "filename": "*q4_k_m-00001-of-00012.gguf",
        "system_prompt": "You are Qwen, a helpful assistant.",
        "generation_defaults": {
            "n_ctx": 0,          
            "n_gpu_layers": -1
        }
    },
    "unsloth/Qwen2.5-VL-72B-Instruct-GGUF": {
        "description": "Vision Language Model.",
        "task": "image-to-text",
        "filename": "*Q4_K_M.gguf",
        "projector_filename": "*mmproj*.gguf",
        "chat_handler": "llama_cpp.llama_chat_format.Qwen2VLChatHandler",
        "generation_defaults": {
            "n_ctx": 0,          
            "n_gpu_layers": -1
        }
    },
    "Qwen/Qwen3-32B-GGUF": {
        "description": "Generation model. GGUF Q4_K_M.",
        "task": "text-generation",
        "filename": "*Q4_K_M.gguf",
        "system_prompt": "You are Qwen, a helpful assistant.",
        "generation_defaults": {
            "n_ctx": 0,          
            "n_gpu_layers": -1
        }
    }
}